{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import base64\n",
    "import datetime\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from hume.client import AsyncHumeClient\n",
    "from hume.empathic_voice.chat.socket_client import ChatConnectOptions, ChatWebsocketConnection\n",
    "from hume.empathic_voice.chat.types import SubscribeEvent\n",
    "from hume.empathic_voice.types import UserInput\n",
    "from hume.core.api_error import ApiError\n",
    "from hume import MicrophoneInterface, Stream\n",
    "\n",
    "class WebSocketHandler:\n",
    "    \"\"\"Handler for containing the EVI WebSocket and associated socket handling behavior.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Construct the WebSocketHandler, initially assigning the socket to None and the byte stream to a new Stream object.\"\"\"\n",
    "        self.socket = None\n",
    "        self.byte_strs = Stream.new()\n",
    "\n",
    "    def set_socket(self, socket: ChatWebsocketConnection):\n",
    "        \"\"\"Set the socket.\n",
    "        \n",
    "        This method assigns the provided asynchronous WebSocket connection\n",
    "        to the instance variable `self.socket`. It is invoked after successfully\n",
    "        establishing a connection using the client's connect method.\n",
    "\n",
    "        Args:\n",
    "            socket (ChatWebsocketConnection): EVI asynchronous WebSocket returned by the client's connect method.\n",
    "        \"\"\"\n",
    "        self.socket = socket\n",
    "\n",
    "    async def on_open(self):\n",
    "        \"\"\"Logic invoked when the WebSocket connection is opened.\"\"\"\n",
    "        print(\"WebSocket connection opened.\")\n",
    "\n",
    "    async def on_message(self, message: SubscribeEvent):\n",
    "        \"\"\"Callback function to handle a WebSocket message event.\n",
    "        \n",
    "        This asynchronous method decodes the message, determines its type, and \n",
    "        handles it accordingly. Depending on the type of message, it \n",
    "        might log metadata, handle user or assistant messages, process\n",
    "        audio data, raise an error if the message type is \"error\", and more.\n",
    "\n",
    "        This method interacts with the following message types to demonstrate logging output to the terminal:\n",
    "        - [chat_metadata](https://dev.hume.ai/reference/empathic-voice-interface-evi/chat/chat#receive.Chat%20Metadata.type)\n",
    "        - [user_message](https://dev.hume.ai/reference/empathic-voice-interface-evi/chat/chat#receive.User%20Message.type)\n",
    "        - [assistant_message](https://dev.hume.ai/reference/empathic-voice-interface-evi/chat/chat#receive.Assistant%20Message.type)\n",
    "        - [audio_output](https://dev.hume.ai/reference/empathic-voice-interface-evi/chat/chat#receive.Audio%20Output.type)\n",
    "\n",
    "        Args:\n",
    "            data (SubscribeEvent): This represents any type of message that is received through the EVI WebSocket, formatted in JSON. See the full list of messages in the API Reference [here](https://dev.hume.ai/reference/empathic-voice-interface-evi/chat/chat#receive).\n",
    "        \"\"\"\n",
    "\n",
    "        # Create an empty dictionary to store expression inference scores\n",
    "        scores = {}\n",
    "\n",
    "        if message.type == \"chat_metadata\":\n",
    "            message_type = message.type.upper()\n",
    "            chat_id = message.chat_id\n",
    "            chat_group_id = message.chat_group_id\n",
    "            text = f\"<{message_type}> Chat ID: {chat_id}, Chat Group ID: {chat_group_id}\"\n",
    "        elif message.type in [\"user_message\", \"assistant_message\"]:\n",
    "            role = message.message.role.upper()\n",
    "            message_text = message.message.content\n",
    "            text = f\"{role}: {message_text}\"\n",
    "            if message.from_text is False:\n",
    "                scores = dict(message.models.prosody.scores)\n",
    "        elif message.type == \"audio_output\":\n",
    "            message_str: str = message.data\n",
    "            message_bytes = base64.b64decode(message_str.encode(\"utf-8\"))\n",
    "            await self.byte_strs.put(message_bytes)\n",
    "            return\n",
    "        elif message.type == \"error\":\n",
    "            error_message: str = message.message\n",
    "            error_code: str = message.code\n",
    "            raise ApiError(f\"Error ({error_code}): {error_message}\")\n",
    "        else:\n",
    "            message_type = message.type.upper()\n",
    "            text = f\"<{message_type}>\"\n",
    "        \n",
    "        # Print the formatted message\n",
    "        self._print_prompt(text)\n",
    "\n",
    "        # Extract and print the top 3 emotions inferred from user and assistant expressions\n",
    "        if len(scores) > 0:\n",
    "            top_3_emotions = self._extract_top_n_emotions(scores, 3)\n",
    "            self._print_emotion_scores(top_3_emotions)\n",
    "            print(\"\")\n",
    "        else:\n",
    "            print(\"\")\n",
    "        \n",
    "    async def on_close(self):\n",
    "        \"\"\"Logic invoked when the WebSocket connection is closed.\"\"\"\n",
    "        print(\"WebSocket connection closed.\")\n",
    "\n",
    "    async def on_error(self, error):\n",
    "        \"\"\"Logic invoked when an error occurs in the WebSocket connection.\n",
    "        \n",
    "        See the full list of errors [here](https://dev.hume.ai/docs/resources/errors).\n",
    "\n",
    "        Args:\n",
    "            error (Exception): The error that occurred during the WebSocket communication.\n",
    "        \"\"\"\n",
    "        print(f\"Error: {error}\")\n",
    "\n",
    "    def _print_prompt(self, text: str) -> None:\n",
    "        \"\"\"Print a formatted message with a timestamp.\n",
    "\n",
    "        Args:\n",
    "            text (str): The message text to be printed.\n",
    "        \"\"\"\n",
    "        now = datetime.datetime.now(tz=datetime.timezone.utc)\n",
    "        now_str = now.strftime(\"%H:%M:%S\")\n",
    "        print(f\"[{now_str}] {text}\")\n",
    "\n",
    "    def _extract_top_n_emotions(self, emotion_scores: dict, n: int) -> dict:\n",
    "        \"\"\"\n",
    "        Extract the top N emotions based on confidence scores.\n",
    "\n",
    "        Args:\n",
    "            emotion_scores (dict): A dictionary of emotions and their corresponding confidence scores.\n",
    "            n (int): The number of top emotions to extract.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the top N emotions as keys and their raw scores as values.\n",
    "        \"\"\"\n",
    "        # Convert the dictionary into a list of tuples and sort by the score in descending order\n",
    "        sorted_emotions = sorted(emotion_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "        # Extract the top N emotions\n",
    "        top_n_emotions = {emotion: score for emotion, score in sorted_emotions[:n]}\n",
    "\n",
    "        return top_n_emotions\n",
    "\n",
    "    def _print_emotion_scores(self, emotion_scores: dict) -> None:\n",
    "        \"\"\"\n",
    "        Print the emotions and their scores in a formatted, single-line manner.\n",
    "\n",
    "        Args:\n",
    "            emotion_scores (dict): A dictionary of emotions and their corresponding confidence scores.\n",
    "        \"\"\"\n",
    "        # Format the output string\n",
    "        formatted_emotions = ' | '.join([f\"{emotion} ({score:.2f})\" for emotion, score in emotion_scores.items()])\n",
    "        \n",
    "        # Print the formatted string\n",
    "        print(f\"|{formatted_emotions}|\")\n",
    "    \n",
    "\n",
    "async def sending_handler(socket: ChatWebsocketConnection):\n",
    "    \"\"\"Handle sending a message over the socket.\n",
    "\n",
    "    This method waits 3 seconds and sends a UserInput message, which takes a `text` parameter as input.\n",
    "    - https://dev.hume.ai/reference/empathic-voice-interface-evi/chat/chat#send.User%20Input.type\n",
    "    \n",
    "    See the full list of messages to send [here](https://dev.hume.ai/reference/empathic-voice-interface-evi/chat/chat#send).\n",
    "\n",
    "    Args:\n",
    "        socket (ChatWebsocketConnection): The WebSocket connection used to send messages.\n",
    "    \"\"\"\n",
    "    # Wait 3 seconds before executing the rest of the method\n",
    "    await asyncio.sleep(3)\n",
    "\n",
    "    # Construct a user input message\n",
    "    # user_input_message = UserInput(text=\"Hello there!\")\n",
    "\n",
    "    # Send the user input as text to the socket\n",
    "    # await socket.send_user_input(user_input_message)\n",
    "\n",
    "async def main() -> None:\n",
    "    # Retrieve any environment variables stored in the .env file\n",
    "    load_dotenv()\n",
    "\n",
    "    # Retrieve the API key, Secret key, and EVI config id from the environment variables\n",
    "    HUME_API_KEY = os.getenv(\"HUME_API_KEY\")\n",
    "    HUME_SECRET_KEY = os.getenv(\"HUME_SECRET_KEY\")\n",
    "    HUME_CONFIG_ID = os.getenv(\"HUME_CONFIG_ID\")\n",
    "\n",
    "    # Initialize the asynchronous client, authenticating with your API key\n",
    "    client = AsyncHumeClient(api_key=HUME_API_KEY)\n",
    "\n",
    "    # Define options for the WebSocket connection, such as an EVI config id and a secret key for token authentication\n",
    "    # See the full list of query parameters here: https://dev.hume.ai/reference/empathic-voice-interface-evi/chat/chat#request.query\n",
    "    options = ChatConnectOptions(config_id=HUME_CONFIG_ID, secret_key=HUME_SECRET_KEY)\n",
    "\n",
    "    # Instantiate the WebSocketHandler\n",
    "    websocket_handler = WebSocketHandler()\n",
    "\n",
    "    # Open the WebSocket connection with the configuration options and the handler's functions\n",
    "    async with client.empathic_voice.chat.connect_with_callbacks(\n",
    "        options=options,\n",
    "        on_open=websocket_handler.on_open,\n",
    "        on_message=websocket_handler.on_message,\n",
    "        on_close=websocket_handler.on_close,\n",
    "        on_error=websocket_handler.on_error\n",
    "    ) as socket:\n",
    "\n",
    "        # Set the socket instance in the handler\n",
    "        websocket_handler.set_socket(socket)\n",
    "\n",
    "        # Create an asynchronous task to continuously detect and process input from the microphone, as well as play audio\n",
    "        microphone_task = asyncio.create_task(\n",
    "            MicrophoneInterface.start(\n",
    "                socket,\n",
    "                allow_user_interrupt=False,\n",
    "                byte_stream=websocket_handler.byte_strs\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Create an asynchronous task to send messages over the WebSocket connection\n",
    "        message_sending_task = asyncio.create_task(sending_handler(socket))\n",
    "        \n",
    "        # Schedule the coroutines to occur simultaneously\n",
    "        await asyncio.gather(microphone_task, message_sending_task)\n",
    "\n",
    "# Execute the main asynchronous function using asyncio's event loop\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
